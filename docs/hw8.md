## Project Idea:

### How do we spot bias in data?
If we can remove bias in data, will it help learners to be more unbiased?
* Pre-process the data by removing biased sensitive features
* minimize the weight of these biased features

### How do we improve learners explanability?
* Given that there are lots of learners out there, how could we improve the learners so 
it could be more explainable?
* How do we create AI output that is human-friendly? (AI that layman coild easily interpret)
  - **explain to justify**: the decisions made by utilising an underlying model should be explained in order to increase their justifiability;
  - **explain to control**: explanations should enhance the transparency of a model and its functioning, allowing its debugging and the identification of potential flaws; 
  - **explain to improve**: explanations should help scholars improve the accuracy and effimciency of their models;
  - **explain to discover**: explanations should support the extraction of novel knowledge and
    the learning of relationships and patterns

## Methods
* Compairing the bias dataset and unbias dataset, anaylsis the characteristic of these data set, finding what a raw unbias dataset should look like.
* Create script/program to process the bias dataset, is the ouput raw dataset seems to be unbias?
* Compare the processed dataset and the unbias dataset on their outputs that produced by a learner, are they similar?
